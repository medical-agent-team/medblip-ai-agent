#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Doctor Agent - Multi-agent systemì˜ ì˜ì‚¬ ì—ì´ì „íŠ¸

AGENTS.md ëª…ì„¸ì— ë”°ë¥¸ ì—­í• :
- ì§„ë‹¨ ì¶”ë¡ ê³¼ ê¶Œì¥ì‚¬í•­ ì œê³µ
- ë™ë£Œ ì˜ê²¬ í‰ê°€ ë° í”¼ë“œë°±ì— ëŒ€í•œ ë…¼í‰
- ë°˜ë³µì ìœ¼ë¡œ ì¶œë ¥ ê°œì„ 
"""

import os
import logging
from typing import Dict, Any, List, Optional
from langchain_core.messages import HumanMessage, SystemMessage

from app.core.llm_factory import get_llm_for_agent
from app.core.observability import get_callbacks
from app.agents.conversation_manager import CaseContext, DoctorOpinion
from app.agents.prompts.doctor_prompts import (
    DOCTOR_ANALYSIS_PROMPT,
    DOCTOR_CRITIQUE_PROMPT,
    DOCTOR_REASONING_PROMPT
)

logger = logging.getLogger(__name__)


class DoctorAgent:
    """
    Multi-agent systemì˜ Doctor Agent

    AGENTS.md ëª…ì„¸ì— ë”°ë¥¸ ì—­í• :
    - ì§„ë‹¨ ì¶”ë¡ ê³¼ ê¶Œì¥ì‚¬í•­ ì œê³µ
    - ë™ë£Œ ì˜ê²¬ í‰ê°€ ë° í”¼ë“œë°±ì— ëŒ€í•œ ë…¼í‰
    - ë°˜ë³µì ìœ¼ë¡œ ì¶œë ¥ ê°œì„ 
    """

    def __init__(self,
                 doctor_id: str,
                 openai_api_key: Optional[str] = None):
        logger.info(f"ğŸ‘¨â€âš•ï¸ DoctorAgent {doctor_id} ì´ˆê¸°í™” ì‹œì‘")

        self.doctor_id = doctor_id
        self.specialty = "ì¼ë°˜ì˜"  # ëª¨ë“  DoctorëŠ” ì¼ë°˜ì˜
        self.api_key = openai_api_key or os.getenv("OPENAI_API_KEY")

        # LLM ì´ˆê¸°í™” - vLLM/Langfuse ì§€ì›
        logger.info(f"ğŸ”‘ {doctor_id} LLM ì´ˆê¸°í™” ì¤‘ (endpoint: {os.getenv('OPENAI_API_BASE', 'OpenAI API')})")
        callbacks = get_callbacks()
        self.llm = get_llm_for_agent(
            agent_type="doctor",
            api_key=self.api_key,
            callbacks=callbacks
        )
        logger.info(f"âœ… {doctor_id} LLM ì´ˆê¸°í™” ì™„ë£Œ (Langfuse: {len(callbacks)} callbacks)")

        # ì˜ì‚¬ë³„ íˆìŠ¤í† ë¦¬ (ë¼ìš´ë“œë³„ ì˜ê²¬ ê¸°ë¡)
        self.opinion_history: List[Dict[str, Any]] = []

        logger.info(f"âœ… DoctorAgent {doctor_id} ({self.specialty}) ì´ˆê¸°í™” ì™„ë£Œ")

    def provide_opinion(self,
                       case_context: CaseContext,
                       round_number: int,
                       peer_opinions: Optional[Dict[str, DoctorOpinion]] = None,
                       supervisor_feedback: Optional[str] = None) -> DoctorOpinion:
        """
        ì‚¬ë¡€ì— ëŒ€í•œ ì˜í•™ì  ì˜ê²¬ ì œê³µ

        Args:
            case_context: í™˜ì ì‚¬ë¡€ ì»¨í…ìŠ¤íŠ¸
            round_number: í˜„ì¬ ë¼ìš´ë“œ ë²ˆí˜¸
            peer_opinions: ì´ì „ ë¼ìš´ë“œì˜ ë™ë£Œ ì˜ê²¬ë“¤
            supervisor_feedback: Supervisorì˜ í”¼ë“œë°±

        Returns:
            ì˜ì‚¬ì˜ ì˜ê²¬ (DoctorOpinion)
        """
        logger.info(f"ğŸ©º {self.doctor_id} ë¼ìš´ë“œ {round_number} ì˜ê²¬ ì œê³µ ì‹œì‘")

        try:
            # ì²« ë²ˆì§¸ ë¼ìš´ë“œì¸ì§€ í™•ì¸
            is_first_round = round_number == 1 or not peer_opinions

            if is_first_round:
                # ì²« ë²ˆì§¸ ë¼ìš´ë“œ: ì´ˆê¸° ë¶„ì„
                opinion = self._provide_initial_opinion(case_context, round_number)
            else:
                # í›„ì† ë¼ìš´ë“œ: ë™ë£Œ ì˜ê²¬ê³¼ í”¼ë“œë°±ì„ ê³ ë ¤í•œ ì—…ë°ì´íŠ¸
                opinion = self._provide_updated_opinion(
                    case_context, round_number, peer_opinions, supervisor_feedback
                )

            # íˆìŠ¤í† ë¦¬ì— ê¸°ë¡
            self.opinion_history.append({
                "round": round_number,
                "opinion": opinion,
                "timestamp": self._get_timestamp()
            })

            logger.info(f"âœ… {self.doctor_id} ë¼ìš´ë“œ {round_number} ì˜ê²¬ ì œê³µ ì™„ë£Œ")
            return opinion

        except Exception as e:
            logger.error(f"âŒ {self.doctor_id} ì˜ê²¬ ì œê³µ ì‹¤íŒ¨: {str(e)}")

            # ê¸°ë³¸ ì˜ê²¬ ë°˜í™˜
            fallback_opinion = DoctorOpinion(
                hypotheses=["ì¶”ê°€ ê²€í†  í•„ìš”"],
                diagnostic_tests=["ì „ë¬¸ì˜ ìƒë‹´"],
                reasoning=f"ì˜ê²¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                critique_of_peers=""
            )

            self.opinion_history.append({
                "round": round_number,
                "opinion": fallback_opinion,
                "error": str(e),
                "timestamp": self._get_timestamp()
            })

            return fallback_opinion

    def _provide_initial_opinion(self,
                                case_context: CaseContext,
                                round_number: int) -> DoctorOpinion:
        """ì²« ë²ˆì§¸ ë¼ìš´ë“œ ì´ˆê¸° ì˜ê²¬ ì œê³µ"""
        logger.info(f"ğŸ” {self.doctor_id} ì´ˆê¸° ì˜ê²¬ ë¶„ì„ ì¤‘")

        # ì‚¬ë¡€ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        analysis_prompt = self._build_initial_analysis_prompt(case_context)

        # LLMì„ í†µí•œ ì˜ê²¬ ìƒì„±
        response = self.llm.invoke([
            SystemMessage(content=DOCTOR_ANALYSIS_PROMPT.format(
                doctor_id=self.doctor_id,
                specialty=self.specialty
            )),
            HumanMessage(content=analysis_prompt)
        ])

        # Log doctor output
        logger.info(f"ğŸ©º [{self.doctor_id}] ë¼ìš´ë“œ {round_number} ì´ˆê¸° ë¶„ì„ ê²°ê³¼:")
        logger.info(f"ğŸ“ Raw LLM Response: {response.content}")

        # ì‘ë‹µ íŒŒì‹±
        parsed_opinion = self._parse_doctor_response(response.content, round_number)

        # Log parsed opinion
        logger.info(f"ğŸ“Š [{self.doctor_id}] íŒŒì‹±ëœ ì˜ê²¬:")
        logger.info(f"   - ê°€ì„¤: {parsed_opinion.get('hypotheses', [])}")
        logger.info(f"   - ì§„ë‹¨ê²€ì‚¬: {parsed_opinion.get('diagnostic_tests', [])}")
        logger.info(f"   - ì¶”ë¡ : {parsed_opinion.get('reasoning', '')[:200]}...")

        return parsed_opinion

    def _provide_updated_opinion(self,
                                case_context: CaseContext,
                                round_number: int,
                                peer_opinions: Dict[str, DoctorOpinion],
                                supervisor_feedback: Optional[str]) -> DoctorOpinion:
        """í›„ì† ë¼ìš´ë“œ ì—…ë°ì´íŠ¸ëœ ì˜ê²¬ ì œê³µ"""
        logger.info(f"ğŸ”„ {self.doctor_id} ì˜ê²¬ ì—…ë°ì´íŠ¸ ì¤‘ (ë¼ìš´ë“œ {round_number})")

        # ì´ì „ ì˜ê²¬ ê°€ì ¸ì˜¤ê¸°
        previous_opinion = self._get_previous_opinion()

        # ì—…ë°ì´íŠ¸ëœ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        update_prompt = self._build_update_analysis_prompt(
            case_context, previous_opinion, peer_opinions, supervisor_feedback, round_number
        )

        # LLMì„ í†µí•œ ì—…ë°ì´íŠ¸ëœ ì˜ê²¬ ìƒì„±
        response = self.llm.invoke([
            SystemMessage(content=DOCTOR_CRITIQUE_PROMPT.format(
                doctor_id=self.doctor_id,
                specialty=self.specialty,
                round_number=round_number
            )),
            HumanMessage(content=update_prompt)
        ])

        # Log doctor output for update
        logger.info(f"ğŸ”„ [{self.doctor_id}] ë¼ìš´ë“œ {round_number} ì—…ë°ì´íŠ¸ ë¶„ì„ ê²°ê³¼:")
        logger.info(f"ğŸ“ Raw LLM Response: {response.content}")

        # ì‘ë‹µ íŒŒì‹±
        parsed_opinion = self._parse_doctor_response(response.content, round_number, is_update=True)

        # Log parsed updated opinion
        logger.info(f"ğŸ“Š [{self.doctor_id}] ì—…ë°ì´íŠ¸ëœ ì˜ê²¬:")
        logger.info(f"   - ê°€ì„¤: {parsed_opinion.get('hypotheses', [])}")
        logger.info(f"   - ì§„ë‹¨ê²€ì‚¬: {parsed_opinion.get('diagnostic_tests', [])}")
        logger.info(f"   - ë™ë£Œ ë¹„íŒ: {parsed_opinion.get('critique_of_peers', '')[:100]}...")

        return parsed_opinion

    def _build_initial_analysis_prompt(self, case_context: CaseContext) -> str:
        """ì´ˆê¸° ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        prompt = f"""
        í™˜ì ì‚¬ë¡€ ë¶„ì„

        **í™˜ì ì •ë³´:**
        - ì¸êµ¬í•™ì  ì •ë³´: {case_context.get('demographics', {})}
        - í˜„ì¬ ì¦ìƒ: {case_context.get('symptoms', {})}
        - ê³¼ê±° ë³‘ë ¥: {case_context.get('history', {})}
        - ë³µìš© ì•½ë¬¼: {case_context.get('meds', {})}
        - í™œë ¥ ì§•í›„: {case_context.get('vitals', {})}

        **ì˜ìƒ ì†Œê²¬ (MedBLIP ë¶„ì„):**
        {case_context.get('medblip_findings', {})}

        **ì¶”ê°€ ì •ë³´:**
        {case_context.get('free_text', '')}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:
        1. ê°€ëŠ¥í•œ ì§„ë‹¨ ê°€ì„¤ë“¤ (ìš°ì„ ìˆœìœ„ìˆœ)
        2. ê¶Œì¥ë˜ëŠ” ì§„ë‹¨ ê²€ì‚¬ë“¤ (ìš°ì„ ìˆœìœ„ìˆœ)
        3. ì„ìƒì  ì¶”ë¡  ê³¼ì •
        4. ì£¼ìš” ê³ ë ¤ì‚¬í•­ ë° ê°ë³„ ì§„ë‹¨

        **ì¤‘ìš”:**
        - í™•ì •ì  ì§„ë‹¨ì´ ì•„ë‹Œ ê°€ì„¤ë¡œ ì œì‹œ
        - í™˜ì ì•ˆì „ì„ ìµœìš°ì„  ê³ ë ¤
        - ì¶”ê°€ ê²€ì‚¬ì˜ í•„ìš”ì„± ê°•ì¡°
        """

        return prompt

    def _build_update_analysis_prompt(self,
                                     case_context: CaseContext,
                                     previous_opinion: Optional[DoctorOpinion],
                                     peer_opinions: Dict[str, DoctorOpinion],
                                     supervisor_feedback: Optional[str],
                                     round_number: int) -> str:
        """ì—…ë°ì´íŠ¸ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        # ê¸°ë³¸ ì‚¬ë¡€ ì •ë³´
        base_info = f"""
        í™˜ì ì‚¬ë¡€ (ë¼ìš´ë“œ {round_number})

        **í™˜ì ì •ë³´:**
        - ì¸êµ¬í•™ì  ì •ë³´: {case_context.get('demographics', {})}
        - í˜„ì¬ ì¦ìƒ: {case_context.get('symptoms', {})}
        - ê³¼ê±° ë³‘ë ¥: {case_context.get('history', {})}
        - ë³µìš© ì•½ë¬¼: {case_context.get('meds', {})}
        - MedBLIP ì†Œê²¬: {case_context.get('medblip_findings', {})}
        """

        # ì´ì „ ì˜ê²¬
        previous_section = ""
        if previous_opinion:
            previous_section = f"""
        **ë‚˜ì˜ ì´ì „ ì˜ê²¬:**
        - ê°€ì„¤: {previous_opinion.get('hypotheses', [])}
        - ì§„ë‹¨ ê²€ì‚¬: {previous_opinion.get('diagnostic_tests', [])}
        - ê·¼ê±°: {previous_opinion.get('reasoning', '')}
        """

        # ë™ë£Œ ì˜ê²¬ë“¤
        peer_section = "\n**ë™ë£Œ ì˜ê²¬ë“¤:**\n"
        for doctor_id, opinion in peer_opinions.items():
            if doctor_id != self.doctor_id:  # ìì‹ ì˜ ì˜ê²¬ ì œì™¸
                peer_section += f"""
        {doctor_id}:
        - ê°€ì„¤: {opinion.get('hypotheses', [])}
        - ì§„ë‹¨ ê²€ì‚¬: {opinion.get('diagnostic_tests', [])}
        - ê·¼ê±°: {opinion.get('reasoning', '')}
        """

        # Supervisor í”¼ë“œë°±
        feedback_section = ""
        if supervisor_feedback:
            feedback_section = f"""
        **Supervisor í”¼ë“œë°±:**
        {supervisor_feedback}
        """

        prompt = f"""
        {base_info}
        {previous_section}
        {peer_section}
        {feedback_section}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

        1. **ë™ë£Œ ì˜ê²¬ ë¶„ì„:** ë™ë£Œë“¤ì˜ ì˜ê²¬ì— ëŒ€í•œ í‰ê°€ì™€ ë¹„íŒ
        2. **ì˜ê²¬ ì—…ë°ì´íŠ¸:** ìƒˆë¡œìš´ ì •ë³´ì™€ í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì—…ë°ì´íŠ¸ëœ ì˜ê²¬
        3. **ê·¼ê±° ê°•í™”:** ì—…ë°ì´íŠ¸ëœ ì˜ê²¬ì— ëŒ€í•œ ë” ê°•í™”ëœ ê·¼ê±°
        4. **í•©ì˜ ê°€ëŠ¥ì„±:** ë™ë£Œë“¤ê³¼ì˜ í•©ì˜ ê°€ëŠ¥ì„± í‰ê°€

        **ì—…ë°ì´íŠ¸ ê¸°ì¤€:**
        - ë™ë£Œ ì˜ê²¬ì˜ íƒ€ë‹¹í•œ ë¶€ë¶„ ìˆ˜ìš©
        - ë³¸ì¸ ì˜ê²¬ì˜ ì•½ì  ë³´ì™„
        - ì¶”ê°€ ê³ ë ¤ì‚¬í•­ ë°˜ì˜
        - í™˜ì ì•ˆì „ ìµœìš°ì„  ê³ ë ¤
        """

        return prompt

    def _parse_doctor_response(self,
                              response: str,
                              round_number: int,
                              is_update: bool = False) -> DoctorOpinion:
        """Doctor LLM ì‘ë‹µ íŒŒì‹±"""
        try:
            # ê°„ë‹¨í•œ íŒŒì‹± ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
            lines = [line.strip() for line in response.split('\n') if line.strip()]

            hypotheses = []
            diagnostic_tests = []
            reasoning = response  # ì „ì²´ ì‘ë‹µì„ reasoningìœ¼ë¡œ ì‚¬ìš©
            critique_of_peers = ""

            # í‚¤ì›Œë“œ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ
            current_section = None
            for line in lines:
                line_lower = line.lower()

                if any(keyword in line_lower for keyword in ['ê°€ì„¤', 'ì§„ë‹¨', 'í›„ë³´', 'ê°€ëŠ¥ì„±']):
                    current_section = 'hypotheses'
                elif any(keyword in line_lower for keyword in ['ê²€ì‚¬', 'ì§„ë‹¨ê²€ì‚¬', 'ì¶”ê°€ê²€ì‚¬']):
                    current_section = 'tests'
                elif any(keyword in line_lower for keyword in ['ë™ë£Œ', 'ì˜ê²¬', 'ë¹„íŒ', 'í‰ê°€']):
                    current_section = 'critique'

                # ëª©ë¡ í•­ëª© ì¶”ì¶œ (-, *, 1., 2. ë“±)
                if line.startswith(('-', '*', 'â€¢')) or (len(line) > 2 and line[1] == '.'):
                    item = line.lstrip('-*â€¢0123456789. ').strip()
                    if current_section == 'hypotheses' and item:
                        hypotheses.append(item)
                    elif current_section == 'tests' and item:
                        diagnostic_tests.append(item)

            # ë™ë£Œ ë¹„íŒ ì¶”ì¶œ (ì—…ë°ì´íŠ¸ ë¼ìš´ë“œì¸ ê²½ìš°)
            if is_update:
                critique_keywords = ['ë™ë£Œ', 'ì˜ê²¬', 'í‰ê°€', 'ë¹„íŒ', 'ë¶„ì„']
                critique_lines = []
                for line in lines:
                    if any(keyword in line for keyword in critique_keywords):
                        critique_lines.append(line)
                critique_of_peers = ' '.join(critique_lines)

            # ê¸°ë³¸ê°’ ì„¤ì •
            if not hypotheses:
                hypotheses = [f"{self.specialty} ê´€ì ì—ì„œì˜ ì¢…í•©ì  ê²€í†  í•„ìš”"]

            if not diagnostic_tests:
                diagnostic_tests = ["ì¶”ê°€ ì „ë¬¸ì˜ ìƒë‹´", "ì¢…í•©ì  ì§„ë‹¨ ê²€ì‚¬"]

            return DoctorOpinion(
                hypotheses=hypotheses[:5],  # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
                diagnostic_tests=diagnostic_tests[:5],  # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
                reasoning=reasoning,
                critique_of_peers=critique_of_peers
            )

        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return DoctorOpinion(
                hypotheses=[f"{self.specialty} ê´€ì  ë¶„ì„ ì¤‘ ì˜¤ë¥˜"],
                diagnostic_tests=["ì „ë¬¸ì˜ ì¬ìƒë‹´"],
                reasoning=f"ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                critique_of_peers=""
            )

    def _get_previous_opinion(self) -> Optional[DoctorOpinion]:
        """ì´ì „ ë¼ìš´ë“œì˜ ì˜ê²¬ ë°˜í™˜"""
        if not self.opinion_history:
            return None

        return self.opinion_history[-1].get('opinion')

    def _get_timestamp(self) -> str:
        """í˜„ì¬ ì‹œê°„ ë¬¸ìì—´ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def get_opinion_history(self) -> List[Dict[str, Any]]:
        """ì˜ê²¬ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.opinion_history.copy()

    def reset(self):
        """ì—ì´ì „íŠ¸ ìƒíƒœ ì´ˆê¸°í™”"""
        logger.info(f"ğŸ”„ {self.doctor_id} ìƒíƒœ ì´ˆê¸°í™”")
        self.opinion_history.clear()


def create_doctor_panel(openai_api_key: Optional[str] = None) -> List[DoctorAgent]:
    """
    AGENTS.md ëª…ì„¸ì— ë”°ë¼ ì •í™•íˆ 3ëª…ì˜ Doctor Agent íŒ¨ë„ ìƒì„±
    ëª¨ë“  DoctorëŠ” ì¼ë°˜ì˜ (non-specialized)

    Returns:
        3ëª…ì˜ DoctorAgent ë¦¬ìŠ¤íŠ¸
    """
    logger.info("ğŸ‘¥ Doctor Agent íŒ¨ë„ ìƒì„± ì¤‘...")

    doctors = [
        DoctorAgent("doctor_1", openai_api_key),
        DoctorAgent("doctor_2", openai_api_key),
        DoctorAgent("doctor_3", openai_api_key)
    ]

    logger.info("âœ… 3ëª…ì˜ ì¼ë°˜ì˜ Doctor Agent íŒ¨ë„ ìƒì„± ì™„ë£Œ")
    return doctors