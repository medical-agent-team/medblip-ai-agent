#!/usr/bin/env python
# coding: utf-8

# In[1]:


import streamlit as st
import sys
import os
from PIL import Image
from transformers import BlipForConditionalGeneration, BlipProcessor
from pathlib import Path
from dotenv import load_dotenv
from fpdf import FPDF
from datetime import datetime
import requests

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath('.')))
if project_root not in sys.path:
    sys.path.append(project_root)

from orchestrator.prompts.prompt import ORCHESTRATOR_AGENT_PROMPT
from langchain_aws import ChatBedrock

# In[ ]:


# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì˜ë£Œ AI ìƒë‹´ ì„œë¹„ìŠ¤",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("ğŸ¥ ì˜ë£Œ AI ìƒë‹´")
    st.markdown("---")
    st.markdown("### ìƒë‹´ ì§„í–‰ ë‹¨ê³„")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "conversation_stage" not in st.session_state:
        st.session_state.conversation_stage = "greeting"
    if "collected_info" not in st.session_state:
        st.session_state.collected_info = {}
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = []
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì§„í–‰ ìƒíƒœ í‘œì‹œ
    stages = {
        "greeting": "ğŸ¤ ì¸ì‚¬ ë° ì•ˆë‚´",
        "basic_info": "ğŸ“ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘",
        # "symptoms": "ğŸ©º ì¦ìƒ í™•ì¸",
        # "history": "ğŸ“‹ ë³‘ë ¥ ì¡°ì‚¬",
        # "lifestyle": "ğŸƒâ€â™‚ï¸ ìƒí™œìŠµê´€ í™•ì¸",
        "image_upload": "ğŸ“· ì´ë¯¸ì§€ ì—…ë¡œë“œ",
        "analysis": "ğŸ” ë¶„ì„ ì¤‘",
        "QandA": "â“ Q&A",
        "completed": "âœ… ìƒë‹´ ì™„ë£Œ"
    }

    for stage, description in stages.items():
        if stage == st.session_state.conversation_stage:
            st.markdown(f"**â¤ {description}**")
        else:
            st.markdown(f"   {description}")

    st.markdown("---")
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        for key in ["conversation_stage", "collected_info", "conversation_history", "messages"]:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()


# In[3]:


# BLIP ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def load_blip_model():
    """BLIP ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        model_path = os.path.join(os.getcwd(), "app/model")
        model = BlipForConditionalGeneration.from_pretrained(model_path)
        processor = BlipProcessor.from_pretrained(model_path)
        return model, processor
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None, None

def analyze_xray_image(image, model, processor):
    """X-ray ì´ë¯¸ì§€ë¥¼ BLIP ëª¨ë¸ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            image = Image.open(image)
        
        # ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
        inputs = processor(images=image, return_tensors="pt")
        pixel_values = inputs.pixel_values
        
        # ëª¨ë¸ ì¶”ë¡ 
        generated_ids = model.generate(pixel_values=pixel_values, max_length=50)
        generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        return generated_caption
    except Exception as e:
        return f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_medical_report_pdf(collected_info, conversation_history):
    """ìˆ˜ì§‘ëœ ì˜ë£Œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # PDF ìƒì„±
    pdf = KoreanPDF()
    pdf.add_page()
    
    # ìƒì„± ì¼ì
    current_time = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")
    pdf.add_section("ë³´ê³ ì„œ ìƒì„±ì¼", current_time)
    
    # ê¸°ë³¸ ì •ë³´
    if 'basic_response' in collected_info:
        pdf.add_section("1. ê¸°ë³¸ ì •ë³´", collected_info['basic_response'])
    
    # ì¦ìƒ ì •ë³´
    if 'symptoms' in collected_info:
        pdf.add_section("2. ì£¼ìš” ì¦ìƒ", collected_info['symptoms'])
    
    # ë³‘ë ¥ ì •ë³´
    if 'medical_history' in collected_info:
        pdf.add_section("3. ê³¼ê±° ë³‘ë ¥", collected_info['medical_history'])
    
    # ìƒí™œìŠµê´€
    if 'lifestyle' in collected_info:
        pdf.add_section("4. ìƒí™œìŠµê´€", collected_info['lifestyle'])
    
    # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
    if 'image_analysis' in collected_info:
        pdf.add_section("5. X-ray ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼", collected_info['image_analysis'])
    
    # ìƒë‹´ ìš”ì•½
    ai_responses = []
    for msg in conversation_history:
        if msg.startswith("AI: ") and len(msg) > 20:
            ai_responses.append(msg[4:])
    
    if ai_responses:
        summary_text = ""
        for i, response in enumerate(ai_responses[-3:], 1):
            display_text = response[:300] + "..." if len(response) > 300 else response
            summary_text += f"[ìƒë‹´ {i}] {display_text}\n\n"
        
        pdf.add_section("6. ìƒë‹´ ìš”ì•½", summary_text)
    
    # ì£¼ì˜ì‚¬í•­
    disclaimer = """ë³¸ ë³´ê³ ì„œëŠ” AI ìƒë‹´ ì‹œìŠ¤í…œì— ì˜í•´ ìƒì„±ëœ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ì˜ë£Œì§„ì˜ ì§„ë‹¨ì´ë‚˜ ì²˜ë°©ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ì§„ë‹¨ê³¼ ì¹˜ë£Œë¥¼ ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ì˜ë£Œê¸°ê´€ì„ ë°©ë¬¸í•˜ì—¬ ì „ë¬¸ì˜ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""
    pdf.add_section("7. ì£¼ì˜ì‚¬í•­", disclaimer)
    
    # PDFë¥¼ ë°”ì´íŠ¸ë¡œ ì¶œë ¥í•˜ê³  bytesë¡œ ë³€í™˜
    pdf_output = pdf.output()
    
    # bytearrayë¥¼ bytesë¡œ ë³€í™˜
    if isinstance(pdf_output, bytearray):
        return bytes(pdf_output)
    else:
        return pdf_output

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸ í´ë˜ìŠ¤
class MedicalOrchestrator:
    def __init__(self):
        self.llm = ChatBedrock(
            model_id="us.anthropic.claude-sonnet-4-20250514-v1:0",
            region_name="us-east-1",  # or your region
            temperature=0.0
            )

    def process_conversation(self, user_input, conversation_stage, collected_info, conversation_history, has_image=False):
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ LangChainì„ ì‚¬ìš©í•˜ì—¬ LLMì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
        """
        # ë°ëª¨ìš© ì‘ë‹µ ë¡œì§ (ì‹¤ì œë¡œëŠ” ORCHESTRATOR_AGENT_PROMPTë¥¼ ì‚¬ìš©)
        if conversation_stage == "greeting":
            return {
                "decision": "CONTINUE_CONVERSATION",
                "message": "ì•ˆë…•í•˜ì„¸ìš”! ê±´ê°•ê²€ì§„ ìƒë‹´ì„ ë„ì™€ë“œë¦¬ëŠ” ì˜ë£Œ AIì…ë‹ˆë‹¤. ğŸ˜Š\\n\\në¨¼ì € ê¸°ë³¸ì ì¸ ì •ë³´ë¥¼ ì—¬ì­¤ë³´ê² ìŠµë‹ˆë‹¤. ì„±í•¨ê³¼ ë‚˜ì´ë¥¼ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?",
                "next_stage": "basic_info",
                "collected_info": collected_info
            }
        elif conversation_stage == "basic_info":
            # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            collected_info["basic_response"] = user_input
            return {
                "decision": "CONTINUE_CONVERSATION", 
                "message": f"ê°ì‚¬í•©ë‹ˆë‹¤! í˜„ì¬ ì–´ë–¤ ì¦ìƒì´ë‚˜ ë¶ˆí¸í•œ ì ì´ ìˆìœ¼ì‹ ì§€ ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "next_stage": "symptoms",
                "collected_info": collected_info
            }
        elif conversation_stage == "symptoms":
            collected_info["symptoms"] = user_input
            return {
                "decision": "CONTINUE_CONVERSATION",
                "message": "ì¦ìƒì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ê³¼ê±°ì— í° ë³‘ì„ ì•“ìœ¼ì‹  ì ì´ ìˆê±°ë‚˜ ìˆ˜ìˆ ì„ ë°›ìœ¼ì‹  ê²½í—˜ì´ ìˆë‚˜ìš”?",
                "next_stage": "history", 
                "collected_info": collected_info
            }
        elif conversation_stage == "history":
            collected_info["medical_history"] = user_input
            return {
                "decision": "CONTINUE_CONVERSATION",
                "message": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. í‰ì†Œ í¡ì—°ì´ë‚˜ ìŒì£¼ëŠ” í•˜ì‹œëŠ”ì§€, ê·¸ë¦¬ê³  ìš´ë™ì€ ì–¼ë§ˆë‚˜ ìì£¼ í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.",
                "next_stage": "lifestyle",
                "collected_info": collected_info
            }
        elif conversation_stage == "lifestyle":
            collected_info["lifestyle"] = user_input
            return {
                "decision": "REQUEST_IMAGE",
                "message": "ìƒí™œìŠµê´€ì— ëŒ€í•´ ì˜ ì•Œê² ìŠµë‹ˆë‹¤. ì´ì œ X-ray ì´ë¯¸ì§€ê°€ ìˆìœ¼ì‹œë©´ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ë” ì •í™•í•œ ë¶„ì„ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "next_stage": "image_upload",
                "collected_info": collected_info
            }
        elif conversation_stage == "image_upload":
            if "image_analysis" in collected_info:
                # ì´ë¯¸ì§€ê°€ ì´ë¯¸ ë¶„ì„ëœ ê²½ìš°
                return {
                    "decision": "CONTINUE_CONVERSATION",
                    "message": "ì´ë¯¸ì§€ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    "next_stage": "analysis",
                    "collected_info": collected_info
                }
            else:
                # ì´ë¯¸ì§€ê°€ ì•„ì§ ì—…ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°
                return {
                    "decision": "REQUEST_IMAGE",
                    "message": "X-ray ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´ë¯¸ì§€ ë¶„ì„ í›„ ìƒë‹´ì„ ê³„ì† ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.",
                    "next_stage": "image_upload",
                    "collected_info": collected_info
                }
            
        elif conversation_stage == "analysis":
            # ì´ë¯¸ì§€ ë¶„ì„ í›„ ìƒë‹´ ê³„ì†
            if "image_analysis" in collected_info:
                if user_input == "ë":
                    return {
                        "decision": "END_CONSULTATION",
                        "message": "ìƒë‹´ ì¢…ë£Œ.",
                        "next_stage": "completed",
                        "collected_info": collected_info
                    }
                # prompt
                patient_analysis_context = f"""
                        ë‹¤ìŒì€ í™˜ìì˜ X-ray ì´ë¯¸ì§€ ë¶„ì„ì´ ì™„ë£Œëœ ìƒí™©ì…ë‹ˆë‹¤.

                        **í™˜ì ì •ë³´:**
                        - ê¸°ë³¸ ì •ë³´: {collected_info['basic_response']}
                        - ì¦ìƒ: {collected_info['symptoms']}
                        - ë³‘ë ¥: {collected_info['medical_history']}
                        - ìƒí™œìŠµê´€: {collected_info['lifestyle']}

                        **X-ray ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:**
                        {collected_info["image_analysis"]}

                        ì´ë¯¸ì§€ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ í™˜ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.
                        """
                prompt_variables = {
                    "user_input": user_input,
                    "conversation_stage": conversation_stage,
                    "collected_info": str(collected_info),
                    "has_image": True,
                    "conversation_history": '\n'.join(conversation_history[-5:]) if conversation_history else 'ì—†ìŒ',
                    "patient_analysis_context": patient_analysis_context
                }
                
                messages = ORCHESTRATOR_AGENT_PROMPT.format_messages(**prompt_variables)
                response = self.llm.invoke(messages)
                llm_response = response.content
                
                return {
                    "decision": "CONTINUE_CONVERSATION",
                    "message": llm_response,
                    "next_stage": "analysis",
                    "collected_info": collected_info
                }
            else:
                return {
                    "decision": "CONTINUE_CONVERSATION",
                    "message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì‹œê² ì–´ìš”?",
                    "next_stage": "image_upload",
                    "collected_info": collected_info
                }  
            
        elif conversation_stage == "completed":
            return {
                "decision": "END_CONSULTATION",
                "message": "ìƒë‹´ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ ì£¼ì„¸ìš”!",
                "next_stage": "completed",
                "collected_info": collected_info
            }

class KoreanPDF(FPDF):
    """í•œêµ­ì–´ë¥¼ ì§€ì›í•˜ëŠ” PDF í´ë˜ìŠ¤"""
    
    def __init__(self):
        super().__init__()
        self.font_downloaded = False
        self.setup_korean_font()
    
    def setup_korean_font(self):
        """í•œêµ­ì–´ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        try:
            # í°íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
            font_dir = "fonts"
            os.makedirs(font_dir, exist_ok=True)
            
            # NanumGothic í°íŠ¸ ë‹¤ìš´ë¡œë“œ
            font_file = os.path.join(font_dir, "NanumGothic.ttf")
            
            if not os.path.exists(font_file):
                print("í•œêµ­ì–´ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                try:
                    # GitHubì—ì„œ NanumGothic ë‹¤ìš´ë¡œë“œ
                    font_url = "https://github.com/naver/nanumfont/raw/master/fonts/NanumGothic.ttf"
                    response = requests.get(font_url, timeout=30)
                    response.raise_for_status()
                    
                    with open(font_file, 'wb') as f:
                        f.write(response.content)
                    print("í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                except Exception as e:
                    print(f"í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    return
            
            # í°íŠ¸ ì¶”ê°€
            self.add_font('NanumGothic', '', font_file, uni=True)
            self.font_downloaded = True
            print("í•œêµ­ì–´ í°íŠ¸ ì„¤ì • ì™„ë£Œ!")
            
        except Exception as e:
            print(f"í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.font_downloaded = False
    
    def header(self):
        """PDF í—¤ë”"""
        if self.font_downloaded:
            self.set_font('NanumGothic', size=16)
        else:
            self.set_font('Arial', 'B', 16)
        
        self.ln(10)
        self.cell(0, 10, 'ì˜ë£Œ AI ìƒë‹´ ë³´ê³ ì„œ', 0, 1, 'C')
        self.ln(10)
    
    def add_section(self, title, content):
        """ì„¹ì…˜ ì¶”ê°€"""
        # ìƒˆ í˜ì´ì§€ê°€ í•„ìš”í•œì§€ í™•ì¸
        if self.get_y() > 250:
            self.add_page()
        
        # ì œëª©
        if self.font_downloaded:
            self.set_font('NanumGothic', size=14)
        else:
            self.set_font('Arial', 'B', 12)
        
        self.set_text_color(0, 0, 139)  # ë‹¤í¬ë¸”ë£¨
        self.cell(0, 8, title, 0, 1, 'L')
        self.ln(3)
        
        # ë‚´ìš©
        if self.font_downloaded:
            self.set_font('NanumGothic', size=10)
        else:
            self.set_font('Arial', '', 10)
        
        self.set_text_color(0, 0, 0)  # ê²€ì •
        
        # í…ìŠ¤íŠ¸ ì²˜ë¦¬
        if content and content.strip():
            try:
                # multi_cell ì‚¬ìš©í•´ì„œ ìë™ ì¤„ë°”ê¿ˆ
                self.multi_cell(0, 6, content)
            except Exception as e:
                # multi_cell ì‹¤íŒ¨ì‹œ ê¸°ë³¸ cell ì‚¬ìš©
                lines = content.split('\n')
                for line in lines:
                    if len(line) > 80:
                        # ê¸´ ì¤„ì€ ë¶„í• 
                        words = line.split(' ')
                        current_line = ""
                        for word in words:
                            if len(current_line + word + " ") > 80:
                                if current_line:
                                    self.cell(0, 6, current_line.strip(), 0, 1, 'L')
                                current_line = word + " "
                            else:
                                current_line += word + " "
                        if current_line:
                            self.cell(0, 6, current_line.strip(), 0, 1, 'L')
                    else:
                        self.cell(0, 6, line, 0, 1, 'L')
        
        self.ln(8)
        
        
load_dotenv()

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
orchestrator = MedicalOrchestrator()

# BLIP ëª¨ë¸ ë¡œë“œ
model, processor = load_blip_model()

# In[4]:


# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ¥ ì˜ë£Œ AI ìƒë‹´ ì„œë¹„ìŠ¤")
st.markdown("ê±´ê°•ê²€ì§„ì„ ìœ„í•œ AI ìƒë‹´ì„ ì‹œì‘í•©ë‹ˆë‹¤. í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•´ ì£¼ì„¸ìš”.")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
chat_container = st.container()

with chat_container:
    # ì´ˆê¸° ë©”ì‹œì§€ í‘œì‹œ
    if not st.session_state.messages:
        initial_response = orchestrator.process_conversation(
            "", "greeting", st.session_state.collected_info, 
            st.session_state.conversation_history
        )
        st.session_state.messages.append({"role": "assistant", "content": initial_response["message"]})
        st.session_state.conversation_stage = initial_response["next_stage"]

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.conversation_history.append(f"ì‚¬ìš©ì: {prompt}")

    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            response = orchestrator.process_conversation(
                prompt,
                st.session_state.conversation_stage,
                st.session_state.collected_info,
                st.session_state.conversation_history
            )

            # ì‘ë‹µ í‘œì‹œ
            st.markdown(response["message"])

            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.messages.append({"role": "assistant", "content": response["message"]})
            st.session_state.conversation_stage = response["next_stage"]
            st.session_state.collected_info = response["collected_info"]
            st.session_state.conversation_history.append(f"AI: {response['message']}")

# ì—¬ê¸°ì„œ, st.session_state.conversation_stage == "image_upload"
# ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„¹ì…˜ (image_upload ë‹¨ê³„ì—ì„œë§Œ í‘œì‹œ)
if st.session_state.conversation_stage == "image_upload":
    st.markdown("---")
    st.subheader("ğŸ“· X-ray ì´ë¯¸ì§€ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader(
        "X-ray ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['png', 'jpg', 'jpeg', 'dcm'],
        help="PNG, JPG, JPEG, DICOM í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )

    if uploaded_file is not None:
        # ì´ë¯¸ì§€ í‘œì‹œ
        col1, col2 = st.columns([1, 1])

        with col1:
            st.image(uploaded_file, caption="ì—…ë¡œë“œëœ X-ray ì´ë¯¸ì§€", use_column_width=True)

        with col2:
            st.info("ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            if st.button("ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘", type="primary"):
                if model is not None and processor is not None:
                    # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
                    with st.spinner("AIê°€ X-ray ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        analysis_result = analyze_xray_image(uploaded_file, model, processor)
                    
                    # ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                    st.session_state.collected_info["image_analysis"] = analysis_result
                    st.session_state.conversation_stage = "analysis"        # ë‹¤ìŒ ì„¸ì…˜ìœ¼ë¡œ ë„˜ì–´ê°
                    
                    # ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€ ì¶”ê°€
                    analysis_message = f"""X-ray ì´ë¯¸ì§€ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

**ë¶„ì„ ê²°ê³¼:**
{analysis_result}

ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì¶”ê°€ì ì¸ ìƒë‹´ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì¶”ê°€ë¡œ ì•Œê³  ì‹¶ì€ ë‚´ìš©ì„ ë§ì”€í•´ ì£¼ì„¸ìš”."""

                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": analysis_message
                    })
                    st.rerun()
                else:
                    st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ ì£¼ì„¸ìš”.")

if st.session_state.conversation_stage == "completed":
    st.markdown("---")
    st.subheader("ğŸ“‹ ìƒë‹´ ë³´ê³ ì„œ")
    st.success("ìƒë‹´ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.info("ìƒë‹´ ë‚´ìš©ì„ PDF ë³´ê³ ì„œë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ìˆ˜ì§‘ëœ ì •ë³´ ìš”ì•½ í‘œì‹œ
        if st.session_state.collected_info:
            st.write("**ìˆ˜ì§‘ëœ ì •ë³´:**")
            info_summary = ""
            if 'basic_response' in st.session_state.collected_info:
                info_summary += f"â€¢ ê¸°ë³¸ì •ë³´: {st.session_state.collected_info['basic_response'][:50]}...\n"
            if 'symptoms' in st.session_state.collected_info:
                info_summary += f"â€¢ ì¦ìƒ: {st.session_state.collected_info['symptoms'][:50]}...\n"
            if 'medical_history' in st.session_state.collected_info:
                info_summary += f"â€¢ ë³‘ë ¥: {st.session_state.collected_info['medical_history'][:50]}...\n"
            if 'lifestyle' in st.session_state.collected_info:
                info_summary += f"â€¢ ìƒí™œìŠµê´€: {st.session_state.collected_info['lifestyle'][:50]}...\n"
            if 'image_analysis' in st.session_state.collected_info:
                info_summary += f"â€¢ ì´ë¯¸ì§€ ë¶„ì„: {st.session_state.collected_info['image_analysis'][:50]}...\n"
            
            st.text(info_summary)
    
    with col2:
        if st.button("ğŸ“„ PDF ë³´ê³ ì„œ ìƒì„±", type="primary"):
            try:
                with st.spinner("PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    # PDF ìƒì„±
                    pdf_data = generate_medical_report_pdf(
                        st.session_state.collected_info,
                        st.session_state.conversation_history
                    )
                    
                    # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
                    if not isinstance(pdf_data, bytes):
                        pdf_data = bytes(pdf_data)
                
                # íŒŒì¼ëª… ìƒì„±
                current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"ì˜ë£Œìƒë‹´ë³´ê³ ì„œ_{current_time}.pdf"
                
                st.download_button(
                    label="ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ",
                    data=pdf_data,
                    file_name=filename,
                    mime="application/pdf",
                    type="secondary"
                )
                
                st.success("PDF ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                
                # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
                try:
                    pdf = KoreanPDF()
                    pdf.add_page()
                    test_output = pdf.output()
                    st.info(f"PDF ì¶œë ¥ íƒ€ì…: {type(test_output)}")
                    st.info(f"í°íŠ¸ ë‹¤ìš´ë¡œë“œ ìƒíƒœ: {pdf.font_downloaded}")
                except Exception as debug_e:
                    st.error(f"ë””ë²„ê·¸ ì¤‘ ì˜¤ë¥˜: {debug_e}")
        
# ìˆ˜ì§‘ëœ ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©)
if st.session_state.collected_info:
    with st.expander("ìˆ˜ì§‘ëœ ì •ë³´ í™•ì¸"):
        st.json(st.session_state.collected_info)


# ## Streamlit ì‹¤í–‰ ë°©ë²•
# 
# ìœ„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:
# 
# ```bash
# streamlit run notebooks/first_service.ipynb
# ```
# 
# ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜ í›„ ì‹¤í–‰:
# 
# ```bash
# jupyter nbconvert --to script notebooks/first_service.ipynb
# streamlit run notebooks/first_service.py
# ```
# 
# ## ì£¼ìš” ê¸°ëŠ¥
# 
# 1. **ë‹¨ê³„ë³„ ìƒë‹´ ì§„í–‰**: ì‚¬ì´ë“œë°”ì—ì„œ í˜„ì¬ ì§„í–‰ ë‹¨ê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
# 2. **ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ìƒë‹´
# 3. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: X-ray ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ë¶„ì„ ìš”ì²­
# 4. **ì„¸ì…˜ ê´€ë¦¬**: ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì„¸ì…˜ì— ì €ì¥
# 5. **ì •ë³´ ìˆ˜ì§‘**: ê¸°ë³¸ ì •ë³´, ì¦ìƒ, ë³‘ë ¥, ìƒí™œìŠµê´€ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì§‘
# 
# ## ì‹¤ì œ ë°°í¬ ì‹œ ì¶”ê°€í•  ì‚¬í•­
# 
# - OpenAI API í‚¤ ì„¤ì • ë° LangChain ì—°ë™
# - ì‹¤ì œ ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë¸ ì—°ë™ (medblip ì—ì´ì „íŠ¸)
# - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ìƒë‹´ ê¸°ë¡ ì €ì¥
# - ë³´ì•ˆ ë° ê°œì¸ì •ë³´ ë³´í˜¸ ê°•í™”
