#!/usr/bin/env python
# coding: utf-8

# In[1]:


import streamlit as st
import sys
import os
from PIL import Image
from transformers import BlipForConditionalGeneration, BlipProcessor

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath('.')))
if project_root not in sys.path:
    sys.path.append(project_root)

# from app.orchestrator.prompts.prompt import ORCHESTRATOR_AGENT_PROMPT
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage


# In[ ]:


# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì˜ë£Œ AI ìƒë‹´ ì„œë¹„ìŠ¤",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("ğŸ¥ ì˜ë£Œ AI ìƒë‹´")
    st.markdown("---")
    st.markdown("### ìƒë‹´ ì§„í–‰ ë‹¨ê³„")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "conversation_stage" not in st.session_state:
        st.session_state.conversation_stage = "greeting"
    if "collected_info" not in st.session_state:
        st.session_state.collected_info = {}
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = []
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì§„í–‰ ìƒíƒœ í‘œì‹œ
    stages = {
        "greeting": "ğŸ¤ ì¸ì‚¬ ë° ì•ˆë‚´",
        "basic_info": "ğŸ“ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘",
        # "symptoms": "ğŸ©º ì¦ìƒ í™•ì¸",
        # "history": "ğŸ“‹ ë³‘ë ¥ ì¡°ì‚¬",
        # "lifestyle": "ğŸƒâ€â™‚ï¸ ìƒí™œìŠµê´€ í™•ì¸",
        "image_upload": "ğŸ“· ì´ë¯¸ì§€ ì—…ë¡œë“œ",
        "analysis": "ğŸ” ë¶„ì„ ì¤‘",
        "completed": "âœ… ìƒë‹´ ì™„ë£Œ"
    }

    for stage, description in stages.items():
        if stage == st.session_state.conversation_stage:
            st.markdown(f"**â¤ {description}**")
        else:
            st.markdown(f"   {description}")

    st.markdown("---")
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        for key in ["conversation_stage", "collected_info", "conversation_history", "messages"]:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()


# In[3]:


# BLIP ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def load_blip_model():
    """BLIP ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        model = BlipForConditionalGeneration.from_pretrained("./model")
        processor = BlipProcessor.from_pretrained("./model")
        return model, processor
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None, None

def analyze_xray_image(image, model, processor):
    """X-ray ì´ë¯¸ì§€ë¥¼ BLIP ëª¨ë¸ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        # PIL Imageë¡œ ë³€í™˜
        if not isinstance(image, Image.Image):
            image = Image.open(image)
        
        # ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
        inputs = processor(images=image, return_tensors="pt")
        pixel_values = inputs.pixel_values
        
        # ëª¨ë¸ ì¶”ë¡ 
        generated_ids = model.generate(pixel_values=pixel_values, max_length=50)
        generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        return generated_caption
    except Exception as e:
        return f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸ í´ë˜ìŠ¤
class MedicalOrchestrator:
    def __init__(self):
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”
        # self.llm = ChatOpenAI(temperature=0.7, model="gpt-3.5-turbo")
        pass

    def process_conversation(self, user_input, conversation_stage, collected_info, conversation_history, has_image=False):
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ LangChainì„ ì‚¬ìš©í•˜ì—¬ LLMì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
        """
        # ë°ëª¨ìš© ì‘ë‹µ ë¡œì§ (ì‹¤ì œë¡œëŠ” ORCHESTRATOR_AGENT_PROMPTë¥¼ ì‚¬ìš©)
        if conversation_stage == "greeting":
            return {
                "decision": "CONTINUE_CONVERSATION",
                "message": "ì•ˆë…•í•˜ì„¸ìš”! ê±´ê°•ê²€ì§„ ìƒë‹´ì„ ë„ì™€ë“œë¦¬ëŠ” ì˜ë£Œ AIì…ë‹ˆë‹¤. ğŸ˜Š\\n\\në¨¼ì € ê¸°ë³¸ì ì¸ ì •ë³´ë¥¼ ì—¬ì­¤ë³´ê² ìŠµë‹ˆë‹¤. ì„±í•¨ê³¼ ë‚˜ì´ë¥¼ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?",
                "next_stage": "basic_info",
                "collected_info": collected_info
            }
        elif conversation_stage == "basic_info":
            # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            collected_info["basic_response"] = user_input
            return {
                "decision": "CONTINUE_CONVERSATION", 
                "message": f"ê°ì‚¬í•©ë‹ˆë‹¤! í˜„ì¬ ì–´ë–¤ ì¦ìƒì´ë‚˜ ë¶ˆí¸í•œ ì ì´ ìˆìœ¼ì‹ ì§€ ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "next_stage": "symptoms",
                "collected_info": collected_info
            }
        elif conversation_stage == "symptoms":
            collected_info["symptoms"] = user_input
            return {
                "decision": "CONTINUE_CONVERSATION",
                "message": "ì¦ìƒì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ê³¼ê±°ì— í° ë³‘ì„ ì•“ìœ¼ì‹  ì ì´ ìˆê±°ë‚˜ ìˆ˜ìˆ ì„ ë°›ìœ¼ì‹  ê²½í—˜ì´ ìˆë‚˜ìš”?",
                "next_stage": "history", 
                "collected_info": collected_info
            }
        elif conversation_stage == "history":
            collected_info["medical_history"] = user_input
            return {
                "decision": "CONTINUE_CONVERSATION",
                "message": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. í‰ì†Œ í¡ì—°ì´ë‚˜ ìŒì£¼ëŠ” í•˜ì‹œëŠ”ì§€, ê·¸ë¦¬ê³  ìš´ë™ì€ ì–¼ë§ˆë‚˜ ìì£¼ í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.",
                "next_stage": "lifestyle",
                "collected_info": collected_info
            }
        elif conversation_stage == "lifestyle":
            collected_info["lifestyle"] = user_input
            return {
                "decision": "REQUEST_IMAGE",
                "message": "ìƒí™œìŠµê´€ì— ëŒ€í•´ ì˜ ì•Œê² ìŠµë‹ˆë‹¤. ì´ì œ X-ray ì´ë¯¸ì§€ê°€ ìˆìœ¼ì‹œë©´ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ë” ì •í™•í•œ ë¶„ì„ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "next_stage": "image_upload",
                "collected_info": collected_info
            }
        elif conversation_stage == "analysis":
            # ì´ë¯¸ì§€ ë¶„ì„ í›„ ìƒë‹´ ê³„ì†
            if "image_analysis" in collected_info:
                return {
                    "decision": "CONTINUE_CONVERSATION",
                    "message": f"ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n{user_input}ì— ëŒ€í•œ ì¶”ê°€ ì„¤ëª…ì„ ë“œë¦¬ë©´, ì—…ë¡œë“œí•´ì£¼ì‹  X-ray ì´ë¯¸ì§€ì—ì„œ '{collected_info['image_analysis']}'ê°€ ê´€ì°°ë©ë‹ˆë‹¤.\n\në‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    "next_stage": "analysis",
                    "collected_info": collected_info
                }
            else:
                return {
                    "decision": "CONTINUE_CONVERSATION",
                    "message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì‹œê² ì–´ìš”?",
                    "next_stage": "image_upload",
                    "collected_info": collected_info
                }
        else:
            return {
                "decision": "END_CONSULTATION",
                "message": "ìƒë‹´ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ ì£¼ì„¸ìš”!",
                "next_stage": "completed",
                "collected_info": collected_info
            }

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
orchestrator = MedicalOrchestrator()

# BLIP ëª¨ë¸ ë¡œë“œ
model, processor = load_blip_model()


# In[4]:


# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ¥ ì˜ë£Œ AI ìƒë‹´ ì„œë¹„ìŠ¤")
st.markdown("ê±´ê°•ê²€ì§„ì„ ìœ„í•œ AI ìƒë‹´ì„ ì‹œì‘í•©ë‹ˆë‹¤. í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•´ ì£¼ì„¸ìš”.")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
chat_container = st.container()

with chat_container:
    # ì´ˆê¸° ë©”ì‹œì§€ í‘œì‹œ
    if not st.session_state.messages:
        initial_response = orchestrator.process_conversation(
            "", "greeting", st.session_state.collected_info, 
            st.session_state.conversation_history
        )
        st.session_state.messages.append({"role": "assistant", "content": initial_response["message"]})
        st.session_state.conversation_stage = initial_response["next_stage"]

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.conversation_history.append(f"ì‚¬ìš©ì: {prompt}")

    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            response = orchestrator.process_conversation(
                prompt,
                st.session_state.conversation_stage,
                st.session_state.collected_info,
                st.session_state.conversation_history
            )

            # ì‘ë‹µ í‘œì‹œ
            st.markdown(response["message"])

            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.messages.append({"role": "assistant", "content": response["message"]})
            st.session_state.conversation_stage = response["next_stage"]
            st.session_state.collected_info = response["collected_info"]
            st.session_state.conversation_history.append(f"AI: {response['message']}")

# ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„¹ì…˜ (image_upload ë‹¨ê³„ì—ì„œë§Œ í‘œì‹œ)
if st.session_state.conversation_stage == "image_upload":
    st.markdown("---")
    st.subheader("ğŸ“· X-ray ì´ë¯¸ì§€ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader(
        "X-ray ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['png', 'jpg', 'jpeg', 'dcm'],
        help="PNG, JPG, JPEG, DICOM í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )

    if uploaded_file is not None:
        # ì´ë¯¸ì§€ í‘œì‹œ
        col1, col2 = st.columns([1, 1])

        with col1:
            st.image(uploaded_file, caption="ì—…ë¡œë“œëœ X-ray ì´ë¯¸ì§€", use_column_width=True)

        with col2:
            st.info("ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            if st.button("ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘", type="primary"):
                if model is not None and processor is not None:
                    # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
                    with st.spinner("AIê°€ X-ray ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        analysis_result = analyze_xray_image(uploaded_file, model, processor)
                    
                    # ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                    st.session_state.collected_info["image_analysis"] = analysis_result
                    st.session_state.conversation_stage = "analysis"
                    
                    # ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€ ì¶”ê°€
                    analysis_message = f"""X-ray ì´ë¯¸ì§€ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

**ë¶„ì„ ê²°ê³¼:**
{analysis_result}

ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì¶”ê°€ì ì¸ ìƒë‹´ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì¶”ê°€ë¡œ ì•Œê³  ì‹¶ì€ ë‚´ìš©ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."""

                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": analysis_message
                    })
                    st.rerun()
                else:
                    st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ ì£¼ì„¸ìš”.")

# ìˆ˜ì§‘ëœ ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©)
if st.session_state.collected_info:
    with st.expander("ìˆ˜ì§‘ëœ ì •ë³´ í™•ì¸"):
        st.json(st.session_state.collected_info)


# ## Streamlit ì‹¤í–‰ ë°©ë²•
# 
# ìœ„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:
# 
# ```bash
# streamlit run notebooks/first_service.ipynb
# ```
# 
# ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜ í›„ ì‹¤í–‰:
# 
# ```bash
# jupyter nbconvert --to script notebooks/first_service.ipynb
# streamlit run notebooks/first_service.py
# ```
# 
# ## ì£¼ìš” ê¸°ëŠ¥
# 
# 1. **ë‹¨ê³„ë³„ ìƒë‹´ ì§„í–‰**: ì‚¬ì´ë“œë°”ì—ì„œ í˜„ì¬ ì§„í–‰ ë‹¨ê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
# 2. **ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ìƒë‹´
# 3. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: X-ray ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ë¶„ì„ ìš”ì²­
# 4. **ì„¸ì…˜ ê´€ë¦¬**: ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì„¸ì…˜ì— ì €ì¥
# 5. **ì •ë³´ ìˆ˜ì§‘**: ê¸°ë³¸ ì •ë³´, ì¦ìƒ, ë³‘ë ¥, ìƒí™œìŠµê´€ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì§‘
# 
# ## ì‹¤ì œ ë°°í¬ ì‹œ ì¶”ê°€í•  ì‚¬í•­
# 
# - OpenAI API í‚¤ ì„¤ì • ë° LangChain ì—°ë™
# - ì‹¤ì œ ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë¸ ì—°ë™ (medblip ì—ì´ì „íŠ¸)
# - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ìƒë‹´ ê¸°ë¡ ì €ì¥
# - ë³´ì•ˆ ë° ê°œì¸ì •ë³´ ë³´í˜¸ ê°•í™”
