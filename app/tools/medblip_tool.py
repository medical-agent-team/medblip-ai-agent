#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
MedBLIP Tool - LangChain Toolë¡œ êµ¬í˜„ëœ MedBLIP ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤
"""

import os
import logging
from typing import Optional, Union, Dict, Any
from PIL import Image
import torch
from pydantic import Field
from transformers import BlipForConditionalGeneration, BlipProcessor

from langchain.tools import BaseTool
from langchain_core.callbacks import CallbackManagerForToolRun

from app.core.model_utils import load_medblip_model

# Docker ë¡œê·¸ì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


class MedBLIPTool(BaseTool):
    """
    MedBLIP ëª¨ë¸ì„ LangChain Toolë¡œ ë˜í•‘
    ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ì„ ìœ„í•œ ë„êµ¬
    """

    name: str = "medblip_analyzer"
    description: str = """
    ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤.
    X-ray, CT, MRI ë“±ì˜ ì˜ë£Œ ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ì˜í•™ì  ì†Œê²¬ì„ ì œê³µí•©ë‹ˆë‹¤.
    ì…ë ¥: PIL Image ê°ì²´ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ
    ì¶œë ¥: ì˜ë£Œ ì˜ìƒì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    model: Optional[Any] = Field(default=None, exclude=True)
    processor: Optional[Any] = Field(default=None, exclude=True)
    model_loaded: bool = Field(default=False, exclude=True)


    def __init__(self, **kwargs):
        logger.info("ğŸš€ MedBLIPTool ì´ˆê¸°í™” ì‹œì‘")
        super().__init__(**kwargs)
        self._load_model()

    def _load_model(self):
        """MedBLIP ëª¨ë¸ ë¡œë“œ"""
        logger.info("ğŸ“¥ MedBLIP ëª¨ë¸ ë¡œë”© ì‹œë„ ì¤‘...")
        try:
            model, processor, resolved_path = load_medblip_model()
            if model is not None and processor is not None:
                self.model = model
                self.processor = processor
                self.model_loaded = True
                logger.info(f"âœ… MedBLIP ëª¨ë¸ ë¡œë”© ì„±ê³µ: {resolved_path}")
            else:
                logger.warning("âš ï¸ MedBLIP ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ - ë°ëª¨ ëª¨ë“œë¡œ ë™ì‘")
                self.model_loaded = False
        except Exception as e:
            logger.error(f"âŒ MedBLIP ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
            object.__setattr__(self, 'model_loaded', False)

    def _run(
        self,
        image_input: Union[str, Image.Image],
        run_manager: Optional[CallbackManagerForToolRun] = None,
    ) -> str:
        """ë„êµ¬ ì‹¤í–‰ ë©”ì„œë“œ"""
        # run_managerëŠ” LangChain ì½œë°±ìš©ì´ì§€ë§Œ í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        _ = run_manager  # Suppress unused variable warning
        logger.info("ğŸ”§ LangChain Tool ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ì´ë¯¸ì§€ ë¶„ì„ í˜¸ì¶œ")
        try:
            return self.analyze_medical_image(image_input)
        except Exception as e:
            logger.error(f"âŒ Tool ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    def analyze_medical_image(
        self,
        image_input: Union[str, Image.Image],
        max_length: int = 100,
        num_beams: int = 5
    ) -> str:
        """
        ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰

        Args:
            image_input: PIL Image ê°ì²´ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            max_length: ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
            num_beams: Beam searchë¥¼ ìœ„í•œ ë¹” ìˆ˜

        Returns:
            ì˜ë£Œ ì˜ìƒ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
        """
        logger.info("ğŸ” ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘")

        if not self.model_loaded:
            logger.warning("âš ï¸ MedBLIP ëª¨ë¸ ë¯¸ë¡œë“œ - ë°ëª¨ ëª¨ë“œë¡œ ë¶„ì„")
            return self._demo_analysis()

        try:
            # ì´ë¯¸ì§€ ì¤€ë¹„
            logger.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
            if isinstance(image_input, str):
                image = Image.open(image_input).convert('RGB')
                logger.info(f"ğŸ“ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ: {image_input}")
            elif isinstance(image_input, Image.Image):
                image = image_input.convert('RGB')
                logger.info("ğŸ–¼ï¸ PIL Image ê°ì²´ ì‚¬ìš©")
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤.")

            # ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
            logger.info("ğŸ”§ ëª¨ë¸ ì…ë ¥ ì¤€ë¹„ ì¤‘...")
            inputs = self.processor(images=image, return_tensors="pt")
            pixel_values = inputs.pixel_values

            # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì´ë™
            if torch.cuda.is_available() and hasattr(self.model, 'to'):
                logger.info("ğŸš€ GPU ê°€ì† ì‚¬ìš©")
                self.model = self.model.to('cuda')
                pixel_values = pixel_values.to('cuda')
            else:
                logger.info("ğŸ’» CPU ì¶”ë¡  ì‚¬ìš©")

            # ì¶”ë¡  ìˆ˜í–‰
            logger.info("ğŸ§  MedBLIP ëª¨ë¸ ì¶”ë¡  ì¤‘...")
            with torch.no_grad():
                generated_ids = self.model.generate(
                    pixel_values=pixel_values,
                    max_length=max_length,
                    num_beams=num_beams,
                    early_stopping=True,
                    do_sample=False
                )

            # ê²°ê³¼ ë””ì½”ë”©
            logger.info("ğŸ“ ë¶„ì„ ê²°ê³¼ ë””ì½”ë”© ì¤‘...")
            generated_text = self.processor.batch_decode(
                generated_ids,
                skip_special_tokens=True
            )[0]

            # í›„ì²˜ë¦¬
            result = self._postprocess_analysis(generated_text)
            logger.info("âœ… ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ")
            return result

        except Exception as e:
            error_msg = f"MedBLIP ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            return self._demo_analysis()

    def _postprocess_analysis(self, raw_text: str) -> str:
        """
        MedBLIP ì›ì‹œ ì¶œë ¥ì„ í›„ì²˜ë¦¬

        Args:
            raw_text: MedBLIP ëª¨ë¸ì˜ ì›ì‹œ ì¶œë ¥

        Returns:
            ì •ë¦¬ëœ ë¶„ì„ ê²°ê³¼
        """
        # ê¸°ë³¸ ì •ë¦¬
        processed_text = raw_text.strip()

        # ì˜ë£Œì§„ì„ ìœ„í•œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
        if processed_text:
            # ì²« ê¸€ì ëŒ€ë¬¸ìë¡œ ë³€ê²½
            if len(processed_text) > 1:
                processed_text = (
                    processed_text[0].upper() + processed_text[1:]
                )
            else:
                processed_text = processed_text.upper()

            # ë§ˆì¹¨í‘œê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if not processed_text.endswith('.'):
                processed_text += '.'

            return processed_text
        else:
            return "ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _demo_analysis(self) -> str:
        """
        ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ë•Œ ì‚¬ìš©í•  ë°ëª¨ ë¶„ì„ ê²°ê³¼

        Returns:
            ë°ëª¨ ë¶„ì„ ê²°ê³¼
        """
        demo_results = [
            "Chest X-ray demonstrates clear lung fields with no acute "
            "cardiopulmonary abnormalities. Heart size appears normal.",
            "The radiographic examination shows normal cardiac silhouette "
            "and no evidence of pneumonia or pleural effusion.",
            "Bilateral lung fields are clear without focal consolidation. "
            "Cardiac outline is within normal limits.",
            "No acute abnormalities detected in the chest radiograph. "
            "Recommend clinical correlation.",
            "The imaging study reveals normal findings consistent with "
            "healthy lung tissue and cardiac structure."
        ]

        import random
        return random.choice(demo_results)

    def get_model_info(self) -> Dict[str, Any]:
        """
        ëª¨ë¸ ì •ë³´ ë°˜í™˜

        Returns:
            ëª¨ë¸ ìƒíƒœ ë° ì •ë³´
        """
        return {
            "model_loaded": self.model_loaded,
            "model_type": "MedBLIP" if self.model_loaded else "Demo Mode",
            "device": (
                "cuda" if torch.cuda.is_available() and self.model_loaded
                else "cpu"
            ),
            "status": "Ready" if self.model_loaded else "Demo Mode - Model not loaded"
        }

    def validate_image(self, image_input: Union[str, Image.Image]) -> bool:
        """
        ì…ë ¥ ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬

        Args:
            image_input: ê²€ì‚¬í•  ì´ë¯¸ì§€

        Returns:
            ì´ë¯¸ì§€ê°€ ìœ íš¨í•œì§€ ì—¬ë¶€
        """
        try:
            if isinstance(image_input, str):
                if not os.path.exists(image_input):
                    return False
                Image.open(image_input)
            elif isinstance(image_input, Image.Image):
                # PIL Image ê°ì²´ì¸ ê²½ìš° ê¸°ë³¸ì ìœ¼ë¡œ ìœ íš¨
                pass
            else:
                return False
            return True
        except Exception:
            return False

    def get_supported_formats(self) -> list:
        """
        ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í˜•ì‹ ë°˜í™˜

        Returns:
            ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í˜•ì‹ ë¦¬ìŠ¤íŠ¸
        """
        return ['PNG', 'JPG', 'JPEG', 'BMP', 'TIFF', 'GIF']


# LangChain Tools í˜¸í™˜ì„±ì„ ìœ„í•œ íŒ©í† ë¦¬ í•¨ìˆ˜
def create_medblip_tool() -> MedBLIPTool:
    """
    MedBLIP ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    Returns:
        MedBLIP ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤
    """
    return MedBLIPTool()


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_analyze(image_input: Union[str, Image.Image]) -> str:
    """
    ë¹ ë¥¸ ì´ë¯¸ì§€ ë¶„ì„ì„ ìœ„í•œ í¸ì˜ í•¨ìˆ˜

    Args:
        image_input: ë¶„ì„í•  ì´ë¯¸ì§€

    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    tool = create_medblip_tool()
    return tool.analyze_medical_image(image_input)


def batch_analyze(image_inputs: list) -> list:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ ë°°ì¹˜ ë¶„ì„

    Args:
        image_inputs: ë¶„ì„í•  ì´ë¯¸ì§€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸

    Returns:
        ê° ì´ë¯¸ì§€ì˜ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    tool = create_medblip_tool()
    results = []

    for image_input in image_inputs:
        try:
            result = tool.analyze_medical_image(image_input)
            results.append(result)
        except Exception as e:
            results.append(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

    return results
